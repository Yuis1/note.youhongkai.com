---
{"dg-publish":true,"permalink":"/CS计算机科学/机器学习/机器学习常见归一化方法及实现/","noteIcon":"","created":"2022-08-02T20:05:33.574+08:00","updated":"2024-04-24T00:23:46.926+08:00"}
---


原文： https://www.likecs.com/show-204855397.html

归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为标量。 在多种计算中都经常用到这种方法。在对数据进行算法训练时，由于数据的问题可能导致算法的效果并不理想，这时候可以考虑一下对数据进行归一化方法。

比较常用的又线性归一化，0 均值归一化，以及其他数学函数演变而来的归一化方法。下面列出我所用过的归一化方法。

1.  **线性归一化—Min-Max** **归一化。公式如下**

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzkxMi8zNTJjNjE2MDJjZDA0MWY2YTNlMzI4OWVhM2M0NjU2MC5wbmc=)

Xnorm 是归一化后的值，Xmax，Xmin 为归一化前数据的最大值和最小值。该方法把数据压缩到区间 [0, 1] 之间，是原数据的等比缩放。如果最大值和最小值相等需要注意是没法归一化的。所有的值相等没有区别。

例子：元数据：DataFrame

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzg2MS9kMzllYzNhN2M4MzM0ZWM5YmFjZjliODU4ZWQ2N2JmNS5wbmc=)

归一化代码：

def my_max_min(x):

    return (x-min(x))/(max(x)-min(x))

df = df.agg(my_max_min)

         Sklearn 库实现 Max-Min 归一化：

from sklearn import preprocessing

      min_max_scaler = preprocessing.MinMaxScaler()

Xnorm = min_max_scaler.fit_transform(df)

print(Xnorm)# <class 'numpy.ndarray'>

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzIxMi9mNWNiYjIzNDkzZjdhNTdkMTI0MDlhMjc3NTU5NTU3Yy5wbmc=)

可以看到和上面自己写的函数一模一样，只是输出的格式是 ndarray 格式。

注：在不涉及距离度量、协方差计算、数据不符合正太分布的时候，可以尝试这种归一化方法。

1.  **0** **均值归一化：公式如下**

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzc0OC9lZGVkNzNmYTQ4MTBmZTdkYzZjZWNmNjE5OGZlNzYxNC5wbmc=)

x 是原始数据， u 是原始数据的均值，σ原始数据的标准差。0 均值归一化方法将原始数据集归一化为均值为 0、方差 1 的数据集.

例子：

def my_mean_norm(x):

    return (x-np.mean(x))/np.std(x)

df = df.agg(my_mean_norm)

print(df)

min_max_scaler = preprocessing.StandardScaler()

Xnorm = min_max_scaler.fit_transform(df)

print(Xnorm)

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzY3NS82ZDQ3NzY4ODU4YzJlN2I3ZTAwOTdiNzVlMzQyOTNlMy5wbmc=)

注：在分类、聚类算法中，需要使用距离来度量相似性的时候、或者使用 PCA 技术进行降维的时候，第二种方法 (Z-score standardization) 表现更好。

1.  **Atan()** **归一化：公式如下：**

**y=atan(x)*2/PI**

画出曲线如下图：

X = np.linspace(-10, 10, 100)

y = [math.atan(x)*2/math.pi for x in X]# math.atan(x) x 不能是数组只能是一个值

plt.plot(X, y)

plt.show()

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzQxNy82NmFkZjY4NDRlZGZkZmYyNzJkMWE5YzViNWU2Yjg4MS5wbmc=)

可以看到此函数把数据压缩有 (-1, 1) 之内了。

1.  **Log10()** **压缩数据，公式如下：（或者对应其他数为底的数据压缩都可以）**

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzMzNi8wZWZjYjExZDhkZWRmMjljYzlhM2JkYWY4YzQ5YWRiOC5wbmc=)

def my_log(x):

    return np.log10(x) / np.log10(max(x))

df = df.agg(my_log)

print(df)

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzYyNC9mZWFhZTZjYjdjYWFmZGUwYTJkNTgyYmFlNGI3NjdiMC5wbmc=)

**注意：除以 log10(max)****，max** **为样本数据最大值，并且所有的数据都要大于等于 1****，这样才能保证归一化后的数据在 [0-1]** **之间，适用范围有限。**

1.  **模糊量化模式，公式如下：**

1/2+1/2*sin(pi/(max-min)*(x-(max-min)/2))

归一化：

def my_mohu(x):

    return 1/2.0+np.sin((math.pi**(x-(max(x)-min(x))/2.0))/(max(x)-min(x)))/2.0

df = df.agg(my_mohu)

print(df)

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzQ0MS9lNjY0MzI3ZGQyYWE1YWZhNWY2OGVjYzU0YTczODRlOS5wbmc=)

下面几个在神经网络里面用的 ** 函数，是为了增加非线性因素，有时候也可以考虑一下对数据的压缩转换。

1.  **Logistics** **转换，也就是 sigmoid 函数。**

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzYwMi85MThmZTU0MjVjNzMzMmYxNWM4MTVjYmMwZTQ3NGE0Mi5wbmc=)

         函数图形：

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzg4MS85MzA3NmE5ZDhjNzU5ZjVhOWExMTFhNTA3NzJmNDQ2MS5wbmc=)

1.  **tanh** **函数**

**公式如下：**

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzIwMy84NjNhZjNmOTA4NWQ4MmY2NDUyMmU5NTg4Yzk0OGY5My5wbmc=)

函数图形：

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzQ5Mi9lMTY0NmU1NzM1NDkwOTkxZGRiMDhlMThiNjA1OWQ2Yy5wbmc=)

1.  **ReLU** **函数，公式如下：**

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzUzMS80NzY3OGE2MzNmOWJhMDc1ZjE5MGRhYWJjZTIyMjEyYi5wbmc=)

函数图形：

![](https://www.likecs.com/default/index/img?u=aHR0cHM6Ly9waWFuc2hlbi5jb20vaW1hZ2VzLzUwNi83ZjM0MzYzMzU2NGIzODk5MTE4OThiNTlmMWRlOTBkYS5wbmc=)

原文链接：来源网络，如有侵犯到您的权益请联系 zengyin969@gmail.com 进行下架处理